<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>WebAR Auto-Détection</title>

  <script src="https://aframe.io/releases/1.4.2/aframe.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/mind-ar@1.2.2/dist/mindar-image-aframe.prod.js"></script>
  <script src="https://cdn.jsdelivr.net/gh/c-frame/aframe-extras@7.0.0/dist/aframe-extras.min.js"></script>

  <style>
    body { margin: 0; overflow: hidden; font-family: sans-serif; }
    #overlay {
      position: absolute; top: 0; left: 0; width: 100%; height: 100%;
      background: rgba(0,0,0,0.85); z-index: 999;
      display: flex; flex-direction: column; justify-content: center; align-items: center;
      transition: opacity 0.5s;
    }
    #loading { color: white; margin-top: 10px; font-size: 0.9rem;}
    #start-btn {
      padding: 15px 40px; font-size: 1.2rem; font-weight: bold;
      color: white; background: #ff0055; border: none; border-radius: 30px; 
      cursor: pointer; display: none; /* Caché tant que le chargement n'est pas fini */
    }
    .hidden { opacity: 0; pointer-events: none; }
  </style>

  <script>
    // --- SHADER CHROMAKEY (FOND VERT) ---
    AFRAME.registerShader('chromakey', {
      schema: {
        src: {type: 'map'},
        color: {default: {x: 0.0, y: 1.0, z: 0.0}, type: 'vec3', is: 'uniform'},
        transparent: {default: true, is: 'uniform'},
        threshold: {default: 0.15, type: 'float', is: 'uniform'},
        smoothness: {default: 0.05, type: 'float', is: 'uniform'}
      },
      init: function (data) {
        this.material = new THREE.ShaderMaterial({
          uniforms: {
            texture: {type: 't', value: undefined},
            color: {type: 'c', value: new THREE.Color(data.color.x, data.color.y, data.color.z)},
            threshold: {type: 'f', value: data.threshold},
            smoothness: {type: 'f', value: data.smoothness}
          },
          vertexShader: `
            varying vec2 vUv;
            void main() { vUv = uv; gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0); }
          `,
          fragmentShader: `
            uniform sampler2D texture; uniform vec3 color; uniform float threshold; uniform float smoothness; varying vec2 vUv;
            void main() {
              vec4 tex = texture2D(texture, vUv);
              float dist = distance(tex.rgb, color);
              float alpha = smoothstep(threshold, threshold + smoothness, dist);
              gl_FragColor = vec4(tex.rgb, tex.a * alpha);
            }
          `,
          transparent: true
        });
        this.update(data);
      },
      update: function (data) {
        this.material.uniforms.texture.value = data.src;
        this.material.uniforms.color.value.setRGB(data.color.x, data.color.y, data.color.z);
        this.material.uniforms.threshold.value = data.threshold;
        this.material.uniforms.smoothness.value = data.smoothness;
      }
    });

    // --- CONTROLEUR LOGIQUE ---
    AFRAME.registerComponent('smart-target', {
      init: function() {
        const el = this.el;
        const video = el.querySelector('a-video') || el.querySelector('[material*="shader: chromakey"]'); // Cherche vidéo normale ou chromakey
        const audio = el.querySelector('audio'); // Cherche audio HTML interne si injecté
        
        // On récupère l'ID de l'audio externe s'il existe
        let audioEl = null;
        if (el.dataset.audioId) {
             audioEl = document.getElementById(el.dataset.audioId);
        }

        el.addEventListener('targetFound', () => {
          if(video && video.components.material.shader === 'chromakey') {
             // Astuce: recupère l'élément vidéo DOM depuis la texture
             const vidDom = video.getAttribute('material').src; 
             if(vidDom) vidDom.play();
          }
          if(audioEl) audioEl.play();
        });

        el.addEventListener('targetLost', () => {
          if(video && video.components.material.shader === 'chromakey') {
             const vidDom = video.getAttribute('material').src; 
             if(vidDom) { vidDom.pause(); vidDom.currentTime = 0; }
          }
          if(audioEl) { audioEl.pause(); audioEl.currentTime = 0; }
        });
      }
    });
  </script>
</head>

<body>
  <div id="overlay">
    <div id="loading">Détection des assets...</div>
    <button id="start-btn">Lancer l'expérience</button>
  </div>

  <a-scene 
    mindar-image="imageTargetSrc: ./assets/targets.mind; uiScanning: yes;" 
    color-space="sRGB" renderer="colorManagement: true, physicallyCorrectLights" 
    vr-mode-ui="enabled: false" device-orientation-permission-ui="enabled: false">

    <a-assets id="assets-loader">
      </a-assets>

    <a-camera position="0 0 0" look-controls="enabled: false"></a-camera>

    <a-entity id="targets-container"></a-entity>

  </a-scene>

  <script>
    // =================================================================
    // SCRIPT D'AUTO-DÉTECTION
    // =================================================================
    
    // CONFIGURATION
    const MAX_TARGETS = 10; // Combien de cibles vérifier (ex: de 0 à 9)
    const ASSETS_PATH = './assets/';

    const assetsContainer = document.getElementById('assets-loader');
    const targetsContainer = document.getElementById('targets-container');
    const startBtn = document.getElementById('start-btn');
    const loadingText = document.getElementById('loading');

    // Fonction utilitaire pour vérifier si un fichier existe
    async function checkFileExists(url) {
      try {
        const response = await fetch(url, { method: 'HEAD' });
        return response.ok;
      } catch (error) {
        return false;
      }
    }

    async function initExperience() {
      let assetsCount = 0;

      for (let i = 0; i < MAX_TARGETS; i++) {
        // Chemins potentiels
        const glbPath = `${ASSETS_PATH}${i}.glb`;
        const mp3Path = `${ASSETS_PATH}${i}.mp3`;
        const mp4Path = `${ASSETS_PATH}${i}.mp4`;

        // Vérification en parallèle
        const [hasGlb, hasMp3, hasMp4] = await Promise.all([
          checkFileExists(glbPath),
          checkFileExists(mp3Path),
          checkFileExists(mp4Path)
        ]);

        // Si aucun asset n'existe pour cet index, on continue (ne rien créer)
        if (!hasGlb && !hasMp3 && !hasMp4) continue;

        assetsCount++;
        
        // 1. Création de l'entité Target
        const targetEl = document.createElement('a-entity');
        targetEl.setAttribute('mindar-image-target', `targetIndex: ${i}`);
        targetEl.setAttribute('smart-target', '');
        
        // --- GESTION AUDIO ---
        if (hasMp3) {
          // Créer l'élément <audio> dans a-assets
          const audioId = `audio-${i}`;
          const audioTag = document.createElement('audio');
          audioTag.setAttribute('id', audioId);
          audioTag.setAttribute('src', mp3Path);
          audioTag.setAttribute('preload', 'auto');
          assetsContainer.appendChild(audioTag);
          
          // Lier l'ID à la target
          targetEl.dataset.audioId = audioId;
        }

        // --- GESTION 3D (GLB) ---
        if (hasGlb) {
          const modelEl = document.createElement('a-entity');
          modelEl.setAttribute('gltf-model', glbPath);
          modelEl.setAttribute('rotation', '0 0 0'); // Rotation par défaut
          modelEl.setAttribute('position', '0 0 0');
          modelEl.setAttribute('scale', '0.5 0.5 0.5'); // Echelle par défaut (ajustable si besoin)
          modelEl.setAttribute('animation-mixer', ''); // Lance l'anim auto
          targetEl.appendChild(modelEl);
        }

        // --- GESTION VIDÉO (MP4 CHROMAKEY) ---
        if (hasMp4) {
          // Créer l'élément <video> dans a-assets
          const videoId = `video-${i}`;
          const videoTag = document.createElement('video');
          videoTag.setAttribute('id', videoId);
          videoTag.setAttribute('src', mp4Path);
          videoTag.setAttribute('preload', 'auto');
          videoTag.setAttribute('loop', 'true');
          videoTag.setAttribute('playsinline', '');
          videoTag.setAttribute('webkit-playsinline', '');
          videoTag.setAttribute('muted', ''); // Requis pour autoplay
          videoTag.setAttribute('crossorigin', 'anonymous');
          assetsContainer.appendChild(videoTag);

          // Créer le plan dans la scène
          const planeEl = document.createElement('a-entity');
          planeEl.setAttribute('geometry', 'primitive: plane; width: 1; height: 0.56'); // Ratio 16:9 par défaut
          // On applique le shader chromakey
          planeEl.setAttribute('material', `shader: chromakey; src: #${videoId}; color: 0 1 0;`);
          targetEl.appendChild(planeEl);
        }

        // Ajouter la target complète à la scène
        targetsContainer.appendChild(targetEl);
      }

      // Fin du chargement
      loadingText.style.display = 'none';
      if (assetsCount > 0) {
        startBtn.style.display = 'block';
      } else {
        loadingText.style.display = 'block';
        loadingText.innerText = "Aucun asset (0.glb, 0.mp4...) trouvé.";
      }
    }

    // Lancer le scan au chargement de la page
    initExperience();

    // Gestion du bouton Start
    startBtn.addEventListener('click', () => {
      document.getElementById('overlay').classList.add('hidden');
      
      // Hack iOS pour débloquer tous les médias créés dynamiquement
      document.querySelectorAll('audio, video').forEach(media => {
        media.play().then(() => {
          media.pause();
          media.currentTime = 0;
        }).catch(e => console.log("Media init warning", e));
      });

      document.querySelector('a-scene').systems['mindar-image-system'].start();
    });
  </script>
</body>
</html>